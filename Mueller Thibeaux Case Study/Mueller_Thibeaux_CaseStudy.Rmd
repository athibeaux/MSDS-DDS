---
title: "Mueller_Thibeaux_Case Study"
author: "Thibeaux"
date: "2023-02-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Load libraries and data
```{r}
library(maps)
library(ggplot2)
library(ggthemes)
library(dplyr)
library(stringr)
library(class)
library(caret)
```
Merge datasets
```{r}
beers <- read.csv(file.choose(), header = TRUE, fill = TRUE)
breweries <- read.csv(file.choose(), header = TRUE, fill = TRUE)

merged <- merge(beers, breweries, by.x = "Brewery_id", by.y = "Brew_ID")
```

1.	How many breweries are present in each state?
```{r}
breweries %>% ggplot() + geom_bar(aes(x = State, fill = State)) + ggtitle("Count of Breweries by State")
```
2.	Merge beer data with the breweries data. Print the first 6 observations and the last six observations to check the merged file.  (RMD only, this does not need to be included in the presentation or the deck.)
```{r}
head(merged, 6)
tail(merged, 6)
```
3.	Address the missing values in each column.

Idea: Use Style to predict IBU

According to ChatGPT:

0-20 IBUs: Mild, low bitterness beers such as Scottish ales, brown ales, and cream ales.
20-40 IBUs: Moderately bitter beers such as English bitters, American amber ales, and most lagers.
40-60 IBUs: Fairly bitter beers such as IPAs, American pale ales, and most Belgian ales.
60-80 IBUs: Very bitter beers such as double IPAs, imperial stouts, and some barleywines.
80+ IBUs: Extremely bitter beers such as triple IPAs and some imperial stouts.
```{r}
merged$Bitterness <- cut(merged$IBU, breaks=c(0, 20, 40, 60, 80, 140), labels=c('Mild', 'Moderately Bitter', 'Fairly Bitter', 'Very Bitter', 'Extremely Bitter'))

```

4.	Compute the median alcohol content and international bitterness unit for each state. Plot a bar chart to compare.
5.	Which state has the maximum alcoholic (ABV) beer? Which state has the most bitter (IBU) beer?
```{r}
# Top 5 Highest ABVs
merged %>% 
  group_by(State,Name.x) %>%
  arrange(desc(ABV))%>%
  head(5)%>%
  ggplot(aes(x=reorder(Name.x,ABV),y=ABV, fill=State)) +
  xlab("") + geom_col() + coord_flip() + theme_economist()

# Top 5 Highest IBUs
merged %>% 
  group_by(State,Name.x) %>%
  arrange(desc(IBU))%>%
  head(5)%>%
  ggplot(aes(x=reorder(Name.x,IBU),y=IBU, fill=State)) +
  xlab("Name of Beer")+
  geom_col() + coord_flip() + theme_economist()
```
6.	Comment on the summary statistics and distribution of the ABV variable.
```{r}
summary(merged$ABV)
mean(!is.na(merged$ABV))

merged %>% ggplot() + geom_histogram(aes(x = ABV))
merged %>% ggplot() + geom_boxplot(aes(x = ABV))

# Ale/IPAs

```
7.	Is there an apparent relationship between the bitterness of the beer and its alcoholic content? Draw a scatter plot.  Make your best judgment of a relationship and EXPLAIN your answer.
```{r}
merged %>% ggplot() + geom_point(aes(x = ABV, y = IBU))
```
8.	Budweiser would also like to investigate the difference with respect to IBU and ABV between IPAs (India Pale Ales) and other types of Ale (any beer with “Ale” in its name other than IPA).  You decide to use KNN classification to investigate this relationship.  Provide statistical evidence one way or the other. You can of course assume your audience is comfortable with percentages … KNN is very easy to understand conceptually.
```{r}
# Find IPA and Ale Rows
sum(str_count(merged$Style,"IPA"))
sum(str_count(merged$Style,"Ale"))

merged$IPA <- as.factor(ifelse(grepl("IPA", merged$Style), TRUE, FALSE))
merged$Ale <- as.factor(ifelse(grepl("Ale", merged$Style) & merged$IPA == FALSE, TRUE, FALSE))

summary(merged)

alesNA <- filter(merged, merged$IPA == TRUE | merged$Ale == TRUE)
ales <- alesNA[complete.cases(alesNA),]
ales$AleOrIPA <- as.factor(ifelse(ales$Ale == TRUE, "Ale", "IPA"))
summary(ales)
```
KNN Model
```{r}
# KNN
iterations = 100
splitPerc = .70

masterAcc = matrix(nrow = iterations)
  
for(j in 1:iterations)
{
accs = data.frame(accuracy = numeric(90), k = numeric(90))
trainIndices = sample(1:dim(ales)[1],round(splitPerc * dim(ales)[1]))
train = ales[trainIndices,]
test = ales[-trainIndices,]
classifications = knn(train[,c(4,5)],test[,c(4,5)],train$AleOrIPA, prob = TRUE, k = 30)
  table(classifications,test$AleOrIPA)
  CMknn = confusionMatrix(table(classifications,test$AleOrIPA))
  masterAcc[j] = CMknn$overall[1]
}

MeanAcc = colMeans(masterAcc)
MeanAcc
CMknn$byClass[1]
CMknn$byClass[2]
```
In addition, while you have decided to use KNN to investigate this relationship (KNN is required) you may also feel free to supplement your response to this question with any other methods or techniques you have learned.  Creativity and alternative solutions are always encouraged.  

9.	Knock their socks off!  Find one other useful inference from the data that you feel Budweiser may be able to find value in.  You must convince them why it is important and back up your conviction with appropriate statistical evidence. 


```{r}
usa = map_data("usa")

p <- ggplot() + 
  geom_polygon(data = usa, aes(x = long, y = lat, group = group), fill = "blue", color = "black") + 
  coord_quickmap()

#Dallas Coords
Dallas <- tibble(
  long = c(-96.7970),
  lat = c(32.7767),
  names = c("Dallas")) 

p + geom_point(data = Dallas, aes(x = long, y = lat), shape = 21, color = "black", fill = "yellow", size = 5) +
  geom_text(data = Dallas, aes(x = long, y = lat, label = names), hjust = 0, nudge_x = 1, color = "white")


#Italy Map
italy = map_data("italy")
ggplot(italy, aes(long,lat, group = group)) + 
geom_polygon(fill = "white", color = "black") +
coord_quickmap()
```